<!DOCTYPE html>
<html lang="en">
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice to Haptic Demo</title>
  <style>
    body {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      background: #fafafa;
      font-family: 'Poppins', sans-serif;
      text-align: center;
    }
    h2 {
      margin-bottom: 20px;
    }
    button {
      padding: 14px 28px;
      font-size: 18px;
      border: none;
      border-radius: 10px;
      background: #0078ff;
      color: #fff;
      cursor: pointer;
      transition: 0.2s;
    }
    button:hover {
      background: #005fd4;
      transform: scale(1.05);
    }
    #status {
      margin-top: 20px;
      font-size: 18px;
      color: #333;
      min-height: 28px;
    }
    #heardText {
      margin-top: 10px;
      font-size: 24px;
      font-weight: 600;
      color: #0078ff;
      min-height: 40px;
    }
    .pulse {
      animation: pulse 0.4s ease-in-out;
    }
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.2); }
      100% { transform: scale(1); }
    }
  </style>
</head>
<body>
  <h2>üéôÔ∏è Voice ‚Üí Haptic Demo</h2>
  <button id="startBtn">Start Listening</button>
  <div id="status">Press the button and say something...</div>
  <div id="heardText"></div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const status = document.getElementById('status');
    const heardText = document.getElementById('heardText');

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      status.innerText = "‚ùå Speech recognition not supported in this browser.";
    } else {
      const recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = false;
      recognition.lang = 'en-US';

     recognition.onresult = (event) => {
  const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
  console.log("Heard:", transcript);

  // Show what was heard on screen
  heardText.textContent = transcript;
  heardText.classList.add("pulse");
  setTimeout(() => heardText.classList.remove("pulse"), 400);

  // --- Haptic feedback rules ---
  // If "sam" or "michael" ‚Üí 3 short pulses
  if (transcript.includes("sam") || transcript.includes("michael")) {
    navigator.vibrate([200, 150, 200, 150, 200]);
  }

  // If "susan" or "grace" ‚Üí long 2-second vibration
  else if (transcript.includes("susan") || transcript.includes("grace")) {
    navigator.vibrate(2000); // 2000 ms continuous vibration
  }
};


      recognition.onerror = (e) => {
        console.error("Recognition error:", e);
        status.innerText = "‚ö†Ô∏è Error: " + e.error;
      };

      recognition.onend = () => {
        status.innerText = "Listening stopped. Tap Start to resume.";
      };

      startBtn.addEventListener('click', () => {
        try {
          recognition.start();
          status.innerText = "üé§ Listening... Say 'Hi'";
        } catch (err) {
          console.log("Recognition already started or error:", err);
        }
      });
    }
  </script>
</body>
</html>
